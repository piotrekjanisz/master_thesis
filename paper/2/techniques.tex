% this file is called up by thesis.tex
% content in this file will be fed into the main document

\chapter{Rendering techniques} % top level followed by section, subsection

\graphicspath{{2/figures/}}

% ----------------------- contents from here ------------------------

Output from particle base simulations is list of particles containing positions. It can also contain additional parameters - for example PhysX fluid simulation returns velocity, lifetime and density in addition to position for each particle. 
Traditionally triangle meshes are used for rendering objects. Using this approach requires constructing fluid triangle mesh for given particle positions. This method is called isosurface extraction and will be described in second section of this chapter. 
Another possibility is to render each particle as a point (or a billboard in general) with opacity so that when large amount of particles is rendered the result would give illusion of a smooth surface. Such technique has one major drawback - it does not produces surface prevents us from adding effects of reflection and refraction.
Similar technique is to extract visible surface by rendering each particle as a sphere into depth buffer. This will be described in first section.

\section{Screen space}
\figuremacroW{screen_space}{Screen Space Fluid Rendering}{The figure shows high level overview of the method, taken from \cite{Green2010}}{0.7}
As mentioned before this approach extracts visible surface by rendering each particle into depth buffer. High level overview ot this method is presented on figure~\ref{screen_space} and consists of following steps \cite{laanSainz2009}: rendering depth texture (section~\ref{sec:surfacedepth}) and thickness textures (section~\ref{sec:thickness}), depth smoothing (section~\ref{sec:smoothing}) and assembling fluid surface with rest of the scene (section~\ref{sec:rendering}).

\subsection{Surface depth} \label{sec:surfacedepth}
To obtain fluid surface visible from the viewpoint of camera each particle is rendered as a sphere into depth texture [rysunek]. At each pixel only closest value is kept using hardware depth test. 
To avoid rendering large amount of geometry each particle is rendered as a point sprite and it's depth is generated in fragment shader. This common technique speeds up rendering process significantly as well as improves quality of rendered spheres (as can be seen on figure~\ref{spheres}) because depth values are generated for each pixel. Rendering spheres as point sprites is 10 to 100 times faster comparing to rendering them as triangle meshes (see table~\ref{sphere_speed_comp}).
\figuremacroW{spheres}{Spheres rendered with different methods}{1 - mesh with 128 triangles, 2 - mesh with 512 triangles, 3 - mesh with 2048 triangles, 4 - point sprite with normals generated in fragment shader}{0.5}
\begin{table}[htdp]
\caption[Comparision of sphere rendering methods]{\textbf{Comparision of sphere rendering methods}}
\centering
\begin{tabular}{cr} 
{\bf Method} & {\bf Frames per second} \\ 
\hline 
Mesh, 128 triangles & 20 \\
Mesh, 512 triangles & 6 \\
Mesh, 2048 triangles   & 1 \\
Point Sprites & 200 \\
\end{tabular}
\label{sphere_speed_comp}
\end{table}

\subsection{Smoothing} \label{sec:smoothing}
Although previous step produces surface it's quality is not sufficient. As can be seen on figure~\ref{spheres_no_smoothing} individual spheres can be seen giving fluid surface gelly-like appearance. To remove this artifact some kind of smoothing has to be applied. Section~\ref{sec:gaussiansmoothing} will describe gaussian smoothing and section~\ref{sec:curvatureflowsmoothing} curvature flow smoothing.
\figuremacroW{spheres_no_smoothing}{Fluid surface rendered without smoothing phase}{Individual spheres can be seen, giving surface unnatural appearance}{0.7}

\subsubsection{Gaussian smoothing} \label{sec:gaussiansmoothing}
Most obvious way to smooth values in depth texture is to apply gaussian filter. It's easy to implement and can be computed fast due to it's linear separability. However this filter produces undesired effect of blending drops of fluid with background surfaces (see figure~\ref{gaussian_filter_img}). 
\figuremacroW{gaussian_filter_img}{Fluid surface rendered with Gaussian smoothing}{From left: depth image, depth image after applying Gaussian filter, diffuse shaded surface}{0.7}
Thus edge-preserving filters needs to be used which are also called bilateral filters. Bilateral Gaussian filter is a modification that changes wages of pixels depending on difference between their tonal value ($I(s)$) and tonal value of central pixel ($I(s_0)$). This can be described by following formula (from~\cite{PhamVliet2005}): 
\begin{equation}
\label{bilateral_equation}
O(s_0) = \frac{\sum_{s \in S}f(s, s_0)I(s)}{\sum_{s \in S}f(s, s_0)}
\end{equation}
where 
\begin{equation}
\label{bilateral_weights_equation}
f(s, s_0) = g_s(s-s_0)g_t(I(s)-I(s_0))
\end{equation}
is the bilateral filter for the neighborhood around $s_0$. $g_s$ is a spatial weight, $g_t$ is a tonal weight and they both are Gaussian functions:
\begin{equation}
\label{bilateral_dist_equation}
g_s(s) = g(x, \sigma_S)g(y, \sigma_S)  \quad   g_t(I) = g(I, \sigma_t)
\end{equation}
As can be seen on equation~\ref{bilateral_weights_equation} only change in bilateral filter (in comparison to regular bilateral filter) is introduction of tonal weight $g_t$. This change makes filter space-variant - that means it can't be computed as a product of two one dimensional filters ($g_s$ in equation~\ref{bilateral_dist_equation}). 
Computional complexity of space-variant filters is $O(Nm^d)$ comparing to only $O(Nmd)$ for space-invariant (d is image dimensionality, m is the size of filtering kernel and N is the number of pixels in the image). For smoothing fluid surface kernel with $m = 20$ must be used, which gives for 2 dimensional image about 400 operations for each pixel when using bilateral filtering. In comparison separable implementation requires 40 operations. It turns out however that computing bilateral filter as it was a space-invariant gives good approximation for real time applications (see figure~\ref{bilateral_comp}). Approximation gives some artifacts but they are not visible when fluid is moving and other effects (reflection and refraction) are applied.
\figuremacroW{bilateral_comp}{Comparision of normal bilateral filter with it's separable approximation}{Upper row presents images for bilateral filter and bottom row presents separable approximation.}{0.7}

Bilateral filter has some undesired effect when applied on z-buffer output. The problem is that depth values are not evenly distributed. This mean that difference between two fragments depth values is dependent on their distance to the viewer. As can be seen on equation~\ref{bilateral_weights_equation} bilateral weights takes into account difference between depth values. In result the further surface lies from camera the less edges are preserved (see figure~\ref{edge_preservation}). Alternative technique to Z-buffering is W-buffering which offers better distribution of depth values \cite{Gregory2009}. Some hardware supports W-buffering but most of it doesn't and it doesn't seems to be supported in future. A workaround to this problem was presented in \cite{Dunlop2006}. It customizes projection transformation in vertex shader in way that depth buffer values have linear distribution at the end. 
\figuremacroW{edge_preservation}{Bilateral filtering results for different distances to camera}{The more distant fluid is from viewer the more smoothed its surface is. Also less edges are preserved due to z-buffer used resulting in more particles got blended into background surfaces}{0.7}

Another issue with smoothing using fixed kernel size filter is that further surfaces are more smoothed than closer surfaces (see figure~\ref{edge_preservation}). Solving that problem would require using filter with variable kernel size, depending on fragment distance from viewer. As implementing this efficiently on graphic hardware is hard and the effect is not so irritating this won't be considered any more. Section~\ref{sec:curvatureflowsmoothing} will describe another smoothing technique that doesn't suffer from this problem. 

\subsubsection{Curvature flow smoothing} \label{sec:curvatureflowsmoothing}
This technique was presented in \cite{laanSainz2009}. 

\subsection{Thickness} \label{sec:thickness}
This step is computed to determine how opaque is surface in given point. It is achieved by rendering particles as circles into depth buffer with additive blending enabled. Resulting thickness texture is then smoothed with Gaussian filter (this time regular one). In order to speed up rendering process this texture can be rendered with lower resolution and then applied with linear interpolation. 

\subsection{Rendering} \label{sec:rendering}
Last step assembles fluid surface with background image. As an input it takes fluid depth texture, thickness texture and texture with rest of the scene rendered. 
[TODO normal reconstruction, refraction, reflection, thickness]

\section{Isosurface extraction} \label{sec:isosurfaceextraction}
Classic algorithm for isosurface extraction is marching cubes (see \cite{LorensenCline1987}). It takes 3d array with scalar field values as an input and produces list of triangles. Algorithm divides space into cubes, and proceeds through scalar field taking one cube at a time (each cube consists of 8 vertices with scalar field values). Field value at each cube vertex is tested to be above or under given threshold and then appropriate triangle configuration is taken from lookup table (there are 256 triangle configurations).

This method is not suitable for extraction surface from particles. Firstly scalar field values at cube corners are not given. Secondly visiting each cube is not efficient as most of cubes doesn't contain surface. Several variations of marching cube algorithm were created to overcome those problems. The algorithm used is a multithreaded version of the one presented in \cite{RosenbergBirdwell2008}. This is a surface following version of marching cubes with a fast particle lookup cache technique. 

\subsection{Overview}
Algorithm takes as an input a list of particles positions, particle radius of influence and produces list of triangles. Particle radius of influence is something different than particle size (or simply particle radius), because its value is usually greater. This is motivated by the fact that we want particles 

TODO obrazek kulek które się stapiają - był taki na necie
TODO opisać fazy algorytmu

\subsection{Block subdivision}
Space is divided into blocks containing cubes. Such a division aims for:
\begin{itemize}
\item Reduce memory consumption - smaller blocks contains less particles and cubes. 
\item Allowing for parallelize algorithm in an easy way - because processing one block is an independent of processing other blocks. 
Blocks are expanded to contain also particles that lies outside them but may influence the field values inside block. That means the block must also contain particles lying within $R_c$ distance from it - this area is called margin and have special treatment, which will be described in next section. Expanding blocks makes parallel processing very easy as there are no dependencies between them.

Block subdivision is a first step of the algorithm. For every particle containing blocks are computed. One particle can be contained in at most 8 blocks due to blocks overlapping. Each block has a list of particles lying within its boundary. 
\end{itemize}

\subsection{Block processing}
Processing of block starts from building a particle lookup cache which will be described in section \ref{sec:lookupcache}. Next surface following marching cube algorithm is run inside block. The algorithm is named marching slices in \cite{RosenbergBirdwell2008}. Block containing $n x n x n$ blocks is divided on n slabs and n+1 slices (TODO rysunek). Division is made in parallel to XY plane. Each slab contains $n x n x 1$ blocks. Slices lies between slabs and serves as a cache. In addition neighboring slabs share slices that lies between them. 

\subsection{Lookup cache}\label{sec:lookupcache}
To compute field value for a given corner all particles that lies within $r_c$ from it have to be found. This task can be accomplished by building space partitioning data structure like octtree (TODO może odnośniki). However .......... . \cite{RosenbergBirdwell2008} presented another to accomplish this task. Presented method does use only integer comparison ........ .


\subsection{Multithreading}
diagram

% ---------------------------------------------------------------------------
% ----------------------- end of thesis sub-document ------------------------
% ---------------------------------------------------------------------------